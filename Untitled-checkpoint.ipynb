{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cb335be-207a-4875-af48-2f7bb058059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de35a9d6-1239-463c-901d-1332cfac46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataset directory path\n",
    "dataset_path = \"bloodtype\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f40b1106-06a1-4bca-8596-4d775480734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image parameters\n",
    "img_size = (128, 128)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4edddc-1ff4-470c-b1cb-26511d52a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerators for training, validation, and testing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,      # Normalize images\n",
    "    validation_split=0.3     # 30% of the data will be split for validation+testing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1345907d-79e2-4e39-a01b-d2bee321e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4205 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c28604d-f7cb-4174-93be-a85e031c245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1796 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_test_gen = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e44c65-e457-48d0-ae23-0021dfe28631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split validation and testing manually (15% each)\n",
    "val_size = len(val_test_gen.filenames) // 2\n",
    "test_gen = val_test_gen\n",
    "test_gen.filenames = test_gen.filenames[val_size:]\n",
    "val_test_gen.filenames = val_test_gen.filenames[:val_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2619d0e1-ee7e-44fa-8107-86e05ea5bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of classes\n",
    "num_classes = len(train_gen.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd86b5b-6aaf-4fbf-8f84-682493422f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayyap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN Model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),  # Dropout for regularization\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b663db0a-09d5-4f65-a568-e6c3aaf12f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49e215a4-2414-4109-b5ff-fc89f0911f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model during training\n",
    "checkpoint = ModelCheckpoint(\"bloodtype_model.keras\", save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fba4dbb-8320-405f-8d20-06c4ad0caf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayyap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 238ms/step - accuracy: 0.3199 - loss: 1.7618 - val_accuracy: 0.7283 - val_loss: 0.7207\n",
      "Epoch 2/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 237ms/step - accuracy: 0.7172 - loss: 0.7798 - val_accuracy: 0.8374 - val_loss: 0.4543\n",
      "Epoch 3/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 239ms/step - accuracy: 0.7825 - loss: 0.5869 - val_accuracy: 0.8396 - val_loss: 0.4192\n",
      "Epoch 4/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 247ms/step - accuracy: 0.8059 - loss: 0.5320 - val_accuracy: 0.8831 - val_loss: 0.3242\n",
      "Epoch 5/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 250ms/step - accuracy: 0.8362 - loss: 0.4460 - val_accuracy: 0.8630 - val_loss: 0.3450\n",
      "Epoch 6/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 249ms/step - accuracy: 0.8596 - loss: 0.3886 - val_accuracy: 0.8820 - val_loss: 0.3113\n",
      "Epoch 7/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 256ms/step - accuracy: 0.8543 - loss: 0.3932 - val_accuracy: 0.8714 - val_loss: 0.3282\n",
      "Epoch 8/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 259ms/step - accuracy: 0.8539 - loss: 0.3907 - val_accuracy: 0.8563 - val_loss: 0.3610\n",
      "Epoch 9/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 277ms/step - accuracy: 0.8744 - loss: 0.3399 - val_accuracy: 0.8903 - val_loss: 0.2800\n",
      "Epoch 10/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 251ms/step - accuracy: 0.8655 - loss: 0.3579 - val_accuracy: 0.8937 - val_loss: 0.2967\n",
      "Epoch 11/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 276ms/step - accuracy: 0.8857 - loss: 0.2999 - val_accuracy: 0.8847 - val_loss: 0.2720\n",
      "Epoch 12/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 273ms/step - accuracy: 0.8974 - loss: 0.2896 - val_accuracy: 0.8508 - val_loss: 0.3924\n",
      "Epoch 13/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 297ms/step - accuracy: 0.8854 - loss: 0.2854 - val_accuracy: 0.9115 - val_loss: 0.2337\n",
      "Epoch 14/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 264ms/step - accuracy: 0.9097 - loss: 0.2592 - val_accuracy: 0.8948 - val_loss: 0.2710\n",
      "Epoch 15/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 289ms/step - accuracy: 0.9158 - loss: 0.2338 - val_accuracy: 0.8909 - val_loss: 0.2656\n",
      "Epoch 16/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 278ms/step - accuracy: 0.9098 - loss: 0.2274 - val_accuracy: 0.8859 - val_loss: 0.3297\n",
      "Epoch 17/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 240ms/step - accuracy: 0.9203 - loss: 0.2150 - val_accuracy: 0.9009 - val_loss: 0.2453\n",
      "Epoch 18/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 236ms/step - accuracy: 0.9287 - loss: 0.1889 - val_accuracy: 0.8758 - val_loss: 0.3052\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_test_gen,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b60d9e5-9b68-4fd6-9f74-74c89b8dc951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9066 - loss: 0.2590\n",
      "Test Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e5223f3-ae27-408c-919e-6b913b876bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"bloodtype_model.keras\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e97bd683-6092-44cb-b295-91b7f5f83df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"bloodtype_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6787b76f-9f03-4e20-854e-2182ca91ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cf85f25-6753-4915-963f-29d173286903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_blood_type(img_path, model=loaded_model):\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    class_index = np.argmax(prediction)\n",
    "    class_labels = list(train_gen.class_indices.keys())\n",
    "\n",
    "    return class_labels[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7b25ee7-be76-4280-9fdd-a33bf67e73f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b43b21f-f8cb-4766-b1dd-ed38f72c7248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Predicted Blood Type: O-\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "result = predict_blood_type(\"Screenshot 2025-02-21 002140.png\")\n",
    "print(\"Predicted Blood Type:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e601d4-9b2a-4fc0-9353-62ad63963e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
